{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f1973be",
   "metadata": {},
   "source": [
    "### Language translation and classification using high-level API pipelines with transformers using several models from Huggingface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef02fcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deepak\\miniconda3\\envs\\NNExperiments\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load pipeline from transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad501ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference text (R) in English to be translated into the other languages. Every word is taken as a token/vector. \n",
    "R = '''My name is Wolfgang and I live in Berlin. I am 65 years old and retired from services.\n",
    "            I love traveling all over the world and collect souvenirs, that are specific to that place. \n",
    "            I give gifts to my colleagues, family, and friends after every trip.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63b12b",
   "metadata": {},
   "source": [
    "# English to Arabic  https://huggingface.co/Helsinki-NLP/opus-mt-en-ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ccc1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deepak\\miniconda3\\envs\\NNExperiments\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'اسمي وولفغانغ وأنا أعيش في برلين، عمري 65 عاماً ومتقاعد من الخدمات، أحب السفر في جميع أنحاء العالم وجمع الهدايا التذكارية، التي هي خاصة بذلك المكان، وأعطي الهدايا لزملائي وعائلتي وأصدقائي بعد كل رحلة.'}]\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-ar\"\n",
    "translator = pipeline(\"translation\", model=model_checkpoint) #translation pipeline provides high API\n",
    "T = translator(R)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81fc41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Helsinki-NLP/opus-mt-en-zh were not used when initializing MarianModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing MarianModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MarianModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at Helsinki-NLP/opus-mt-en-zh were not used when initializing MarianModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing MarianModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MarianModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['T_destination',\n",
       "  '__annotations__',\n",
       "  '__call__',\n",
       "  '__class__',\n",
       "  '__delattr__',\n",
       "  '__dict__',\n",
       "  '__dir__',\n",
       "  '__doc__',\n",
       "  '__eq__',\n",
       "  '__format__',\n",
       "  '__ge__',\n",
       "  '__getattr__',\n",
       "  '__getattribute__',\n",
       "  '__gt__',\n",
       "  '__hash__',\n",
       "  '__init__',\n",
       "  '__init_subclass__',\n",
       "  '__le__',\n",
       "  '__lt__',\n",
       "  '__module__',\n",
       "  '__ne__',\n",
       "  '__new__',\n",
       "  '__reduce__',\n",
       "  '__reduce_ex__',\n",
       "  '__repr__',\n",
       "  '__setattr__',\n",
       "  '__setstate__',\n",
       "  '__sizeof__',\n",
       "  '__str__',\n",
       "  '__subclasshook__',\n",
       "  '__weakref__',\n",
       "  '_apply',\n",
       "  '_auto_class',\n",
       "  '_backward_compatibility_gradient_checkpointing',\n",
       "  '_backward_hooks',\n",
       "  '_backward_pre_hooks',\n",
       "  '_buffers',\n",
       "  '_call_impl',\n",
       "  '_convert_head_mask_to_5d',\n",
       "  '_create_repo',\n",
       "  '_expand_inputs_for_generation',\n",
       "  '_extract_past_from_model_output',\n",
       "  '_forward_hooks',\n",
       "  '_forward_hooks_with_kwargs',\n",
       "  '_forward_pre_hooks',\n",
       "  '_forward_pre_hooks_with_kwargs',\n",
       "  '_from_config',\n",
       "  '_get_backward_hooks',\n",
       "  '_get_backward_pre_hooks',\n",
       "  '_get_decoder_start_token_id',\n",
       "  '_get_files_timestamps',\n",
       "  '_get_logits_processor',\n",
       "  '_get_logits_warper',\n",
       "  '_get_name',\n",
       "  '_get_resized_embeddings',\n",
       "  '_get_resized_lm_head',\n",
       "  '_get_stopping_criteria',\n",
       "  '_hook_rss_memory_post_forward',\n",
       "  '_hook_rss_memory_pre_forward',\n",
       "  '_init_weights',\n",
       "  '_initialize_weights',\n",
       "  '_is_full_backward_hook',\n",
       "  '_is_hf_initialized',\n",
       "  '_keep_in_fp32_modules',\n",
       "  '_keys_to_ignore_on_load_missing',\n",
       "  '_keys_to_ignore_on_load_unexpected',\n",
       "  '_keys_to_ignore_on_save',\n",
       "  '_load_from_state_dict',\n",
       "  '_load_pretrained_model',\n",
       "  '_load_pretrained_model_low_mem',\n",
       "  '_load_state_dict_post_hooks',\n",
       "  '_load_state_dict_pre_hooks',\n",
       "  '_maybe_initialize_input_ids_for_generation',\n",
       "  '_maybe_warn_non_full_backward_hook',\n",
       "  '_merge_criteria_processor_list',\n",
       "  '_modules',\n",
       "  '_named_members',\n",
       "  '_no_split_modules',\n",
       "  '_non_persistent_buffers_set',\n",
       "  '_parameters',\n",
       "  '_prepare_attention_mask_for_generation',\n",
       "  '_prepare_decoder_input_ids_for_generation',\n",
       "  '_prepare_encoder_decoder_kwargs_for_generation',\n",
       "  '_prepare_model_inputs',\n",
       "  '_register_load_state_dict_pre_hook',\n",
       "  '_register_state_dict_hook',\n",
       "  '_reorder_cache',\n",
       "  '_replicate_for_data_parallel',\n",
       "  '_resize_token_embeddings',\n",
       "  '_save_to_state_dict',\n",
       "  '_set_default_torch_dtype',\n",
       "  '_set_gradient_checkpointing',\n",
       "  '_skip_keys_device_placement',\n",
       "  '_slow_forward',\n",
       "  '_state_dict_hooks',\n",
       "  '_state_dict_pre_hooks',\n",
       "  '_tie_encoder_decoder_weights',\n",
       "  '_tie_or_clone_weights',\n",
       "  '_update_model_kwargs_for_generation',\n",
       "  '_upload_modified_files',\n",
       "  '_validate_model_class',\n",
       "  '_validate_model_kwargs',\n",
       "  '_version',\n",
       "  'add_memory_hooks',\n",
       "  'add_module',\n",
       "  'adjust_logits_during_generation',\n",
       "  'apply',\n",
       "  'assisted_decoding',\n",
       "  'base_model',\n",
       "  'base_model_prefix',\n",
       "  'beam_sample',\n",
       "  'beam_search',\n",
       "  'bfloat16',\n",
       "  'buffers',\n",
       "  'call_super_init',\n",
       "  'can_generate',\n",
       "  'children',\n",
       "  'compute_transition_scores',\n",
       "  'config',\n",
       "  'config_class',\n",
       "  'constrained_beam_search',\n",
       "  'contrastive_search',\n",
       "  'cpu',\n",
       "  'create_extended_attention_mask_for_decoder',\n",
       "  'cuda',\n",
       "  'decoder',\n",
       "  'device',\n",
       "  'disable_input_require_grads',\n",
       "  'double',\n",
       "  'dtype',\n",
       "  'dummy_inputs',\n",
       "  'dump_patches',\n",
       "  'enable_input_require_grads',\n",
       "  'encoder',\n",
       "  'estimate_tokens',\n",
       "  'eval',\n",
       "  'extra_repr',\n",
       "  'float',\n",
       "  'floating_point_ops',\n",
       "  'forward',\n",
       "  'framework',\n",
       "  'from_pretrained',\n",
       "  'generate',\n",
       "  'generation_config',\n",
       "  'get_buffer',\n",
       "  'get_decoder',\n",
       "  'get_decoder_input_embeddings',\n",
       "  'get_encoder',\n",
       "  'get_extended_attention_mask',\n",
       "  'get_extra_state',\n",
       "  'get_head_mask',\n",
       "  'get_input_embeddings',\n",
       "  'get_memory_footprint',\n",
       "  'get_output_embeddings',\n",
       "  'get_parameter',\n",
       "  'get_position_embeddings',\n",
       "  'get_submodule',\n",
       "  'gradient_checkpointing_disable',\n",
       "  'gradient_checkpointing_enable',\n",
       "  'greedy_search',\n",
       "  'group_beam_search',\n",
       "  'half',\n",
       "  'init_weights',\n",
       "  'invert_attention_mask',\n",
       "  'ipu',\n",
       "  'is_gradient_checkpointing',\n",
       "  'is_loaded_in_4bit',\n",
       "  'is_loaded_in_8bit',\n",
       "  'is_parallelizable',\n",
       "  'is_quantized',\n",
       "  'load_state_dict',\n",
       "  'main_input_name',\n",
       "  'modules',\n",
       "  'name_or_path',\n",
       "  'named_buffers',\n",
       "  'named_children',\n",
       "  'named_modules',\n",
       "  'named_parameters',\n",
       "  'num_parameters',\n",
       "  'parameters',\n",
       "  'post_init',\n",
       "  'prepare_inputs_for_generation',\n",
       "  'prune_heads',\n",
       "  'push_to_hub',\n",
       "  'register_backward_hook',\n",
       "  'register_buffer',\n",
       "  'register_for_auto_class',\n",
       "  'register_forward_hook',\n",
       "  'register_forward_pre_hook',\n",
       "  'register_full_backward_hook',\n",
       "  'register_full_backward_pre_hook',\n",
       "  'register_load_state_dict_post_hook',\n",
       "  'register_module',\n",
       "  'register_parameter',\n",
       "  'register_state_dict_pre_hook',\n",
       "  'requires_grad_',\n",
       "  'reset_memory_hooks_state',\n",
       "  'resize_decoder_token_embeddings',\n",
       "  'resize_position_embeddings',\n",
       "  'resize_token_embeddings',\n",
       "  'retrieve_modules_from_names',\n",
       "  'reverse_bettertransformer',\n",
       "  'sample',\n",
       "  'save_pretrained',\n",
       "  'set_decoder_input_embeddings',\n",
       "  'set_extra_state',\n",
       "  'set_input_embeddings',\n",
       "  'share_memory',\n",
       "  'shared',\n",
       "  'state_dict',\n",
       "  'supports_gradient_checkpointing',\n",
       "  'tie_weights',\n",
       "  'to',\n",
       "  'to_bettertransformer',\n",
       "  'to_empty',\n",
       "  'train',\n",
       "  'training',\n",
       "  'type',\n",
       "  'warnings_issued',\n",
       "  'xpu',\n",
       "  'zero_grad'],\n",
       " ['T_destination',\n",
       "  '__annotations__',\n",
       "  '__call__',\n",
       "  '__class__',\n",
       "  '__delattr__',\n",
       "  '__dict__',\n",
       "  '__dir__',\n",
       "  '__doc__',\n",
       "  '__eq__',\n",
       "  '__format__',\n",
       "  '__ge__',\n",
       "  '__getattr__',\n",
       "  '__getattribute__',\n",
       "  '__gt__',\n",
       "  '__hash__',\n",
       "  '__init__',\n",
       "  '__init_subclass__',\n",
       "  '__le__',\n",
       "  '__lt__',\n",
       "  '__module__',\n",
       "  '__ne__',\n",
       "  '__new__',\n",
       "  '__reduce__',\n",
       "  '__reduce_ex__',\n",
       "  '__repr__',\n",
       "  '__setattr__',\n",
       "  '__setstate__',\n",
       "  '__sizeof__',\n",
       "  '__str__',\n",
       "  '__subclasshook__',\n",
       "  '__weakref__',\n",
       "  '_apply',\n",
       "  '_auto_class',\n",
       "  '_backward_compatibility_gradient_checkpointing',\n",
       "  '_backward_hooks',\n",
       "  '_backward_pre_hooks',\n",
       "  '_buffers',\n",
       "  '_call_impl',\n",
       "  '_convert_head_mask_to_5d',\n",
       "  '_create_repo',\n",
       "  '_expand_inputs_for_generation',\n",
       "  '_extract_past_from_model_output',\n",
       "  '_forward_hooks',\n",
       "  '_forward_hooks_with_kwargs',\n",
       "  '_forward_pre_hooks',\n",
       "  '_forward_pre_hooks_with_kwargs',\n",
       "  '_from_config',\n",
       "  '_get_backward_hooks',\n",
       "  '_get_backward_pre_hooks',\n",
       "  '_get_decoder_start_token_id',\n",
       "  '_get_files_timestamps',\n",
       "  '_get_logits_processor',\n",
       "  '_get_logits_warper',\n",
       "  '_get_name',\n",
       "  '_get_resized_embeddings',\n",
       "  '_get_resized_lm_head',\n",
       "  '_get_stopping_criteria',\n",
       "  '_hook_rss_memory_post_forward',\n",
       "  '_hook_rss_memory_pre_forward',\n",
       "  '_init_weights',\n",
       "  '_initialize_weights',\n",
       "  '_is_full_backward_hook',\n",
       "  '_is_hf_initialized',\n",
       "  '_keep_in_fp32_modules',\n",
       "  '_keys_to_ignore_on_load_missing',\n",
       "  '_keys_to_ignore_on_load_unexpected',\n",
       "  '_keys_to_ignore_on_save',\n",
       "  '_load_from_state_dict',\n",
       "  '_load_pretrained_model',\n",
       "  '_load_pretrained_model_low_mem',\n",
       "  '_load_state_dict_post_hooks',\n",
       "  '_load_state_dict_pre_hooks',\n",
       "  '_maybe_initialize_input_ids_for_generation',\n",
       "  '_maybe_warn_non_full_backward_hook',\n",
       "  '_merge_criteria_processor_list',\n",
       "  '_modules',\n",
       "  '_named_members',\n",
       "  '_no_split_modules',\n",
       "  '_non_persistent_buffers_set',\n",
       "  '_parameters',\n",
       "  '_prepare_attention_mask_for_generation',\n",
       "  '_prepare_decoder_input_ids_for_generation',\n",
       "  '_prepare_encoder_decoder_kwargs_for_generation',\n",
       "  '_prepare_model_inputs',\n",
       "  '_register_load_state_dict_pre_hook',\n",
       "  '_register_state_dict_hook',\n",
       "  '_reorder_cache',\n",
       "  '_replicate_for_data_parallel',\n",
       "  '_resize_token_embeddings',\n",
       "  '_save_to_state_dict',\n",
       "  '_set_default_torch_dtype',\n",
       "  '_set_gradient_checkpointing',\n",
       "  '_skip_keys_device_placement',\n",
       "  '_slow_forward',\n",
       "  '_state_dict_hooks',\n",
       "  '_state_dict_pre_hooks',\n",
       "  '_tie_encoder_decoder_weights',\n",
       "  '_tie_or_clone_weights',\n",
       "  '_update_model_kwargs_for_generation',\n",
       "  '_upload_modified_files',\n",
       "  '_validate_model_class',\n",
       "  '_validate_model_kwargs',\n",
       "  '_version',\n",
       "  'add_memory_hooks',\n",
       "  'add_module',\n",
       "  'adjust_logits_during_generation',\n",
       "  'apply',\n",
       "  'assisted_decoding',\n",
       "  'base_model',\n",
       "  'base_model_prefix',\n",
       "  'beam_sample',\n",
       "  'beam_search',\n",
       "  'bfloat16',\n",
       "  'buffers',\n",
       "  'call_super_init',\n",
       "  'can_generate',\n",
       "  'children',\n",
       "  'compute_transition_scores',\n",
       "  'config',\n",
       "  'config_class',\n",
       "  'constrained_beam_search',\n",
       "  'contrastive_search',\n",
       "  'cpu',\n",
       "  'create_extended_attention_mask_for_decoder',\n",
       "  'cuda',\n",
       "  'decoder',\n",
       "  'device',\n",
       "  'disable_input_require_grads',\n",
       "  'double',\n",
       "  'dtype',\n",
       "  'dummy_inputs',\n",
       "  'dump_patches',\n",
       "  'enable_input_require_grads',\n",
       "  'encoder',\n",
       "  'estimate_tokens',\n",
       "  'eval',\n",
       "  'extra_repr',\n",
       "  'float',\n",
       "  'floating_point_ops',\n",
       "  'forward',\n",
       "  'framework',\n",
       "  'from_pretrained',\n",
       "  'generate',\n",
       "  'generation_config',\n",
       "  'get_buffer',\n",
       "  'get_decoder',\n",
       "  'get_decoder_input_embeddings',\n",
       "  'get_encoder',\n",
       "  'get_extended_attention_mask',\n",
       "  'get_extra_state',\n",
       "  'get_head_mask',\n",
       "  'get_input_embeddings',\n",
       "  'get_memory_footprint',\n",
       "  'get_output_embeddings',\n",
       "  'get_parameter',\n",
       "  'get_position_embeddings',\n",
       "  'get_submodule',\n",
       "  'gradient_checkpointing_disable',\n",
       "  'gradient_checkpointing_enable',\n",
       "  'greedy_search',\n",
       "  'group_beam_search',\n",
       "  'half',\n",
       "  'init_weights',\n",
       "  'invert_attention_mask',\n",
       "  'ipu',\n",
       "  'is_gradient_checkpointing',\n",
       "  'is_loaded_in_4bit',\n",
       "  'is_loaded_in_8bit',\n",
       "  'is_parallelizable',\n",
       "  'is_quantized',\n",
       "  'load_state_dict',\n",
       "  'main_input_name',\n",
       "  'modules',\n",
       "  'name_or_path',\n",
       "  'named_buffers',\n",
       "  'named_children',\n",
       "  'named_modules',\n",
       "  'named_parameters',\n",
       "  'num_parameters',\n",
       "  'parameters',\n",
       "  'post_init',\n",
       "  'prepare_inputs_for_generation',\n",
       "  'prune_heads',\n",
       "  'push_to_hub',\n",
       "  'register_backward_hook',\n",
       "  'register_buffer',\n",
       "  'register_for_auto_class',\n",
       "  'register_forward_hook',\n",
       "  'register_forward_pre_hook',\n",
       "  'register_full_backward_hook',\n",
       "  'register_full_backward_pre_hook',\n",
       "  'register_load_state_dict_post_hook',\n",
       "  'register_module',\n",
       "  'register_parameter',\n",
       "  'register_state_dict_pre_hook',\n",
       "  'requires_grad_',\n",
       "  'reset_memory_hooks_state',\n",
       "  'resize_decoder_token_embeddings',\n",
       "  'resize_position_embeddings',\n",
       "  'resize_token_embeddings',\n",
       "  'retrieve_modules_from_names',\n",
       "  'reverse_bettertransformer',\n",
       "  'sample',\n",
       "  'save_pretrained',\n",
       "  'set_decoder_input_embeddings',\n",
       "  'set_extra_state',\n",
       "  'set_input_embeddings',\n",
       "  'share_memory',\n",
       "  'shared',\n",
       "  'state_dict',\n",
       "  'supports_gradient_checkpointing',\n",
       "  'tie_weights',\n",
       "  'to',\n",
       "  'to_bettertransformer',\n",
       "  'to_empty',\n",
       "  'train',\n",
       "  'training',\n",
       "  'type',\n",
       "  'warnings_issued',\n",
       "  'xpu',\n",
       "  'zero_grad'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To access a model's methods and attributes, we need to use AutoModel and AutoTokenizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "model = AutoModel.from_pretrained(model_checkpoint)\n",
    "Tokenizer = AutoModel.from_pretrained(model_checkpoint)\n",
    "dir(model),dir(Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f8943a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To see sequence length and hidden_size\n",
    "model.config.max_position_embeddings,model.config.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c912aa4",
   "metadata": {},
   "source": [
    "# English to Chinese (Mandarin) https://huggingface.co/Helsinki-NLP/opus-mt-en-zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fda68db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': '我的名字是沃尔夫冈,我住在柏林。我65岁,退休了,我热爱环游世界各地,收集那里特有的纪念品。每次旅行后,我都会给我的同事、家人和朋友送礼物。'}]\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-zh\"\n",
    "translator = pipeline(\"translation\", model=model_checkpoint)\n",
    "T = translator(R)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd417b5",
   "metadata": {},
   "source": [
    "## Language Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b71a1d1",
   "metadata": {},
   "source": [
    "### The following program from https://huggingface.co/qanastek/51-languages-classifier classifies Arabic, Russian, Mandarin, Polish, and Latvian and a few more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fc10dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "model_name = 'qanastek/51-languages-classifier'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86d135f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = classifier(\"أحب السفر إلى أماكن مختلفة وجمع الهدايا التذكارية. بعد كل رحلة ، أشارك ميورياتي مع العائلة والأصدقاء.\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd915702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'zh-TW', 'score': 0.9998824596405029}]\n"
     ]
    }
   ],
   "source": [
    "res = classifier(\"我喜歡到不同的地方旅行並收集紀念品。每次旅行後，我都會與家人和朋友分享我的回憶。\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "783f6854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'fi-FI', 'score': 0.9999626874923706}]\n"
     ]
    }
   ],
   "source": [
    "res = classifier(\"Mulle meeldib reisida erinevatesse kohtadesse ja koguda suveniire. Pärast iga reisi jagan oma mälestusi pere ja sõpradega.\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90377c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNExperiments",
   "language": "python",
   "name": "nnexperiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
